{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bpnet pipeline saves the model as a .pb file. We have to convert this to an h5 file for compatibility with our pipeline\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Load the SavedModel\n",
    "# model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# # Convert and reset model_path\n",
    "# model_path = f'{base_dir}/resources/model.h5'\n",
    "# if hasattr(model, 'save'):\n",
    "#     model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Filepaths and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for all inputs / outputs\n",
    "base_dir = f'/scratch/users/jgalante/SparseNet/p53'\n",
    "\n",
    "# Paths to resources\n",
    "peaks_bed = f\"{base_dir}/resources/peaks_inliers.bed\"\n",
    "seqs = f'{base_dir}/resources/genome.fa'\n",
    "signal_plus = f\"{base_dir}/resources/experiment_plus.bw\"\n",
    "signal_minus = f\"{base_dir}/resources/experiment_minus.bw\"\n",
    "ctl_plus = f\"{base_dir}/resources/control_plus.bw\"\n",
    "ctl_minus = f\"{base_dir}/resources/control_minus.bw\"\n",
    "negatives_bed = f\"{base_dir}/resources/gc_negatives.bed\"\n",
    "model_path = f'{base_dir}/resources/model.h5'\n",
    "\n",
    "# Output Directory\n",
    "out_dir = f'{base_dir}/results'\n",
    "pwm_root_dir = f\"{out_dir}/pwms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "expansion_factor = 4.0\n",
    "topk_fraction = 0.05\n",
    "center_length = 1000\n",
    "epochs = 3\n",
    "inner_bs = 16384\n",
    "lr = 1e-3\n",
    "\n",
    "# pwm settings\n",
    "num_samples_per_node = 1000\n",
    "num_top_nodes = int(expansion_factor * 64)\n",
    "latent_dim = int(expansion_factor * 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Loci:   0%|          | 0/12845 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Loci: 100%|██████████| 12845/12845 [00:08<00:00, 1557.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data and other information\n",
    "import numpy\n",
    "import os\n",
    "import torch\n",
    "from bpnetlite.io import PeakGenerator\n",
    "from scripts import deterministic_data_loaders as ddl\n",
    "from scripts import models as mds\n",
    "from scripts import SAE_trainer as st\n",
    "from scripts import save_activations as sa\n",
    "from scripts import plot_activation_frequencies as nf\n",
    "from scripts import create_PWM_for_nodes as pwm\n",
    "\n",
    "training_data = PeakGenerator(\n",
    "    peaks = peaks_bed,\n",
    "    negatives = negatives_bed,\n",
    "    sequences = seqs,\n",
    "    signals = [signal_plus, signal_minus],\n",
    "    controls = [ctl_plus, ctl_minus],\n",
    "    chroms = None,\n",
    "    in_window = 2114,\n",
    "    out_window = 1000,\n",
    "    max_jitter = 128,\n",
    "    negative_ratio = 0.33,\n",
    "    reverse_complement = True,\n",
    "    shuffle = True,\n",
    "    min_counts = None,\n",
    "    max_counts = None,\n",
    "    summits = False,\n",
    "    exclusion_lists = None,\n",
    "    random_state = 12345,\n",
    "    pin_memory = True,\n",
    "    num_workers = 0,\n",
    "    batch_size = 64,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "# Initialize the dataloader to pass all peaks through SAEs and capture activations in order of bed file\n",
    "sae_testing_data = ddl.DeterministicPeakGenerator(\n",
    "    peaks=[peaks_bed, negatives_bed],\n",
    "    sequences=seqs,\n",
    "    signals=[signal_plus, signal_minus],\n",
    "    chroms=None,\n",
    "    in_window=2114,\n",
    "    out_window=1000,\n",
    "    pin_memory=True,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SAEs and Notate them with PWMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the trainer object\n",
    "trainer = st.SAETrainer(model_path=model_path, device=\"cuda\", center_len=center_length)\n",
    "\n",
    "# Train an SAE for each layer on all training data with given hyperparameters\n",
    "trainer.train_all(\n",
    "    train_loader=training_data,\n",
    "    sae_cls=mds.SAETopK,\n",
    "    sae_kwargs={\"latent_multiplier\": expansion_factor, \"k_fraction\": topk_fraction},\n",
    "    save_dir=f'{out_dir}/models',\n",
    "    logs_dir=f'{out_dir}/models/logs',\n",
    "    epochs=epochs,\n",
    "    inner_bs=inner_bs,\n",
    "    lr=lr,\n",
    "    log_every=50,\n",
    ")\n",
    "\n",
    "# Load the trained SAEs from disk written by trainer.train_all()\n",
    "sae_models = mds.load_saes_from_dir(save_dir=f'{out_dir}/models', layers=trainer.layers, device=trainer.device)\n",
    "\n",
    "# Run Top-K collection over deterministic data loader\n",
    "meta = sa.collect_topk_indices_to_disk_from_trainer(\n",
    "    trainer=trainer,\n",
    "    sae_models=sae_models,\n",
    "    loader=sae_testing_data,\n",
    "    out_dir=f'{out_dir}/activations',\n",
    ")\n",
    "\n",
    "# Plot node activation frequencies\n",
    "nf.plot_node_activation_frequencies(\n",
    "\tnum_layers = len(trainer.layers), \n",
    "\tlatent_dim = int(64*expansion_factor), \n",
    "\tdata_dir = f'{out_dir}/activations'\n",
    ")\n",
    "\n",
    "pwm.compute_pwms_for_all_layers(\n",
    "    trainer=trainer,\n",
    "    loader=sae_testing_data,\n",
    "    activations_dir=f\"{out_dir}/activations\",\n",
    "    pwm_root_dir=pwm_root_dir,\n",
    "    latent_dim=latent_dim,\n",
    "    num_top_nodes=num_top_nodes,\n",
    "    num_samples_per_node=num_samples_per_node\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot nodes of multiple positions in one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import plot_position_nodes as plotpos\n",
    "\n",
    "layer_to_view = 8\n",
    "pwm_dir_for_layer = f\"{out_dir}/pwms/layer{layer_to_view}\"\n",
    "\n",
    "viz = plotpos.SequenceNodeVisualizer(\n",
    "    activations_dir=f\"{out_dir}/activations\",\n",
    "    pwm_dir=pwm_dir_for_layer,\n",
    "    loader=sae_testing_data,\n",
    ")\n",
    "\n",
    "viz.plot_sample(sample_idx=0, layer_idx=layer_to_view, top_n_nodes=50)\n",
    "# viz.show_position_range_logos(start_pos=160, end_pos=170, threshold=0.0)\n",
    "# viz.show_position_range_logos(start_pos=355, end_pos=365, threshold=0.0)\n",
    "# viz.show_position_range_logos(start_pos=490, end_pos=501, threshold=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot top nodes of multiple positions over all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.show_position_range_all_layers(\n",
    "    sample_idx=0, \n",
    "    start_pos=160, \n",
    "    end_pos=170,\n",
    "    pwm_root_dir=f\"{out_dir}/pwms\",\n",
    "    threshold=0.0,\n",
    "    max_nodes_per_pos=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginalizing a p53 motif in background sequence motif versus p53 sequences in natural context\n",
    "\n",
    "Looking at a p53 motif from one sample and mutating each base pair to see how the nodes and magnitudes react\n",
    "- analyzing to understand diversity of nodes/magnitudes activated with each variant\n",
    "- i.e. do all of these changes get written into magnitudes in the later layers. are they more indexed in earlier layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to take one canonical p53 motif from the samples [CATG CCCGGG ATG]\n",
    "# I need to change each nucleotide to test 16*4 different inputs\n",
    "# I want to track, for each of these inputs, the node and magnitude in each of the motif's positions\n",
    "# I wnat to also track differences in flanking positions\n",
    "\n",
    "# I then want to take a background sequence and marginalize a p53 sequence\n",
    "# I want to test if there are differences in node and magnitude when marginalizing versus comparing to samples with that motif\n",
    "\n",
    "# Okay i couldn't find like any example of the canonical motif that was not in an ERV... which is interesting in itself\n",
    "# We're going to just : chr3:32364186-32364542\n",
    "# chr8:71,530,288-71,531,938 (specific from below)\n",
    "# chr8:68,226,153-72,600,681 (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After I do this and understand some of the results in a controlled environment\n",
    "# I want to do the same to ChromBPNet on the sequences used for variant-Effects\n",
    "# Then can try to make a statement, based on node usage on which sequences might be more biological"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transposon Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p53 binding sites come from ERV events - can our network detect which of these are ERVs\n",
    "# Do these sites look more like marginalized sequences or other...? idk if that question makes sense\n",
    "# Are these mapping errors?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (bpnetlite)",
   "language": "python",
   "name": "bpnetlite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
